{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sonnet_generate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbWXe0ir1x6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing required libraries \n",
        "import numpy as np \n",
        "import tensorflow as tf"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hf5418y15pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "#Reading Data\n",
        "data = open(r'/content/dataset.txt').read()\n",
        "\n",
        "#Making sentences Lower case and spliting it \n",
        "corpus = data.lower().split(\"<eos>\")\n",
        "corpus = corpus[:100]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA94NtaJ18SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning data, removing unwanted symbols.\n",
        "import re\n",
        "for i in range(len(corpus)):\n",
        " corpus[i] = corpus[i].replace(\"\\n\",' ')\n",
        " corpus[i] = corpus[i].replace(\"<eos>\",' ')\n",
        " corpus[i] = re.sub(\"[`~!@#$+%*:().'?-].\\\"\", ' ',corpus[i]) "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOVpx7OA1-pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fitting data on tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow.keras.utils as ku \n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1 \n",
        "\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "        \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]                                                                               \n",
        "label = ku.to_categorical(label, num_classes=total_words)        "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmgcQXnc2EzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import Regularizer\n",
        "#Sequential Model \n",
        "model = Sequential()\n",
        "\n",
        "#Adding layers to the model \n",
        "model.add(Embedding(total_words,240, input_length=max_sequence_len-1))  \n",
        "model.add(Bidirectional(LSTM(150))) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(total_words/2, activation='relu'))\n",
        "model.add(Dense(total_words, activation='softmax')) "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQP1ADuQ2GQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compiling Model \n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])  "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUZx02E72IOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "10ef434c-3355-44f9-be07-0372a87c0fcd"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Checkpoint \n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.82):\n",
        "      model.save('vaibhav.h5')\n",
        "      print(\"\\nReached 80% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "#Training model over certain epoches .\n",
        "model.fit(predictors, label, epochs=1,callbacks = [callbacks], verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 0s 6ms/step - loss: 6.0986 - accuracy: 0.0270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe672964ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD0mJc0WR-8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7d20174-9eed-4a8d-bd77-a2ef3d424b26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZahIz1G2KT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "de9ba4be-9b3c-48ff-90b9-e4e767b5f32f"
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import model_from_json\n",
        "json_file = open('/content/drive/My Drive/jack1.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights('/content/drive/My Drive/model.h5')\n",
        "new_model = loaded_model\n",
        "#Cleaning data, removing unwanted symbols\n",
        "data = open(r'/content/dataset2.txt').read()\n",
        "corpus = data.lower().split(\"<eos>\")\n",
        "import re\n",
        "for i in range(len(corpus)):\n",
        " corpus[i] = corpus[i].replace(\"\\n\",' ')\n",
        " corpus[i] = corpus[i].replace(\"<eos>\",' ')\n",
        " corpus[i] = re.sub(\"[`~!@#$+%*:().'?-].\\\"\", ' ',corpus[i]) \n",
        "\n",
        "sonnet = []  \n",
        "def predict():\n",
        "  seed_len = 14\n",
        "  for _ in range(seed_len): \n",
        "    start_idx = np.random.randint(0, len(corpus))\n",
        "    seed_text = corpus[start_idx]\n",
        "    for i in range(1):\n",
        "      token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "      token_list = pad_sequences([token_list], maxlen= 10, padding='pre')\n",
        "      predicted = new_model.predict_classes(token_list, verbose=0 )\n",
        "      output_word = \"\"\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "      seed_text += \" \" +output_word\n",
        "    sonnet.append(seed_text)\n",
        "  return sonnet\n",
        "\n",
        "d = predict()\n",
        "for i in d :\n",
        "  print(i)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"embedding_input_9:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 10).\n",
            " o ’ er all his limbs ambrosial odours shed  but\n",
            " but feast their souls on ilion ’ s woes to come  charms\n",
            " pale , and unrobed .— faithless ! thou well may'st hide  the\n",
            " turn back ! no man her ‘ witched gift withstands  \n",
            " for if i die and thou repent t ’ have slain me  not\n",
            " but who shall dare , in this refining age  i\n",
            " oh , mother nature ! would that i could run  —\n",
            " o melancholy soul , whom far and near  leaf\n",
            " two happy farmers , learned in love 's lore  \n",
            " no rank malaria stains thine atmosphere  the\n",
            " a silent heart whose silence loves and longs  your\n",
            " as carnal hindrances which held my soul  mantuan\n",
            " if ours be not the laurel , ours the palm  seed\n",
            " thy eyes like searing irons burn out mine  for\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}